---
name: upload packages
# yamllint disable rule:line-length

# Controls when the action will run.
on:        # yamllint disable-line rule:truthy
  # schedule test for nightly build
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    # Note: the defaults are repeated within the 'env' section
    #       of some of the jobs so any change to the default
    #       need to be done (at least) twice!
    inputs:
      download:
        type: choice
        description: 'download location ( dune | lund ) [dune]'
        required: true
        default: 'dune'
        options:
          - dune
          - lund
      upload:
        type: choice
        description: 'upload (none | testpypi | pypi) [none]'
        required: true
        default: 'none'
        options:
          - none
          - pypi
          - testpypi
      branch:
        # note: this should be either 'master' or a tag of the form
        #       vN where 'N' is a legal python package version
        #       e.g. N=2.8.0rc1
        #       otherwise the distributions will not be generated
        #       and the build will fail
        description: 'core tag e.g. (master | v2.8.0) [master]'
        required: true
        default: 'master'
      fembranch:
        # note: this should be either 'master' or a tag of the form
        #       vN where 'N' is a legal python package version
        #       e.g. N=2.8.0rc1
        #       otherwise the distributions will not be generated
        #       and the build will fail
        description: 'fem tag e.g. (master | v2.8.0.1) [master]'
        required: true
        default: 'master'
      runTests:
        type: boolean
        description: run testing scenarios [false]
        required: true
        default: true
      logLevel:
        type: choice
        description: 'Log level [Warning]'
        required: true
        default: 'Warning'
        options:
          - Debug
          - Warning
          - Info
          - error

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # build packages
  build:
    name: build
    runs-on: [ubuntu-latest]
    env:
      DOWNURL: 'https://gitlab.dune-project.org'
      RUNTESTS: ${{ !contains(github.event.inputs.runTests, 'false') }}
    steps:
      - name: downloadLund
        if: github.event.inputs.download == 'lund'
        run: echo "DOWNURL=https://gitlab.maths.lu.se/dune" >> $GITHUB_ENV
      - name: printParameters
        run: |
          echo "Workflow parameters"
          echo "Using github branch   : ${GITHUB_REF#refs/heads/}"
          echo "Using log level       : ${{ github.event.inputs.logLevel }}"
          echo "Using download        : ${{ env.DOWNURL }}"
          echo "Using upload          : ${{ github.event.inputs.upload }}"
          echo "Using dune-core branch: ${{ github.event.inputs.branch }}"
          echo "Using dune-fem  branch: ${{ github.event.inputs.fembranch }}"
          echo "Run tests: ${{ github.event.inputs.runTests }}"
          echo "ref: ${{ github.ref }}"
      - name: starting
        uses: actions/checkout@v3
      - name: Test on dune/dune-testpypi and get the run ID
        uses: codex-/return-dispatch@v1
        id: return_dispatch
        with:
          token: ${{ secrets.Dispatch_Secret }}
          repo: dune-testpypi
          owner: dune-project
          ref: ${{ github.ref }}
          workflow: testing.yml
          workflow_inputs: '{ "logLevel": "${{ github.event.inputs.logLevel }}", "branch": "${{ github.event.inputs.branch }}", "fembranch": "${{ github.event.inputs.fembranch }}", "download": "${{ env.DOWNURL }}", "runTests": "${{ env.RUNTESTS }}" }'
      - name: Await Run ID ${{ steps.return_dispatch.outputs.run_id }}
        uses: Codex-/await-remote-run@v1.0.0
        with:
          token: ${{ secrets.Dispatch_Secret }}
          repo: dune-testpypi
          owner: dune-project
          run_id: ${{ steps.return_dispatch.outputs.run_id }}
          run_timeout_seconds: 7200
          poll_interval_ms: 5000
      - name: download artifacts from dune-testpypi
        uses: dawidd6/action-download-artifact@v3
        with:
          github_token: ${{ secrets.Dispatch_Secret }}
          repo: dune-project/dune-testpypi
          branch: main
          workflow: testing.yml
          workflow_search: true   # find the latest - might fail...
          # not sure but this does not seem to be the correct run_id: ${{ steps.return_dispatch.outputs.run_id }}
          workflow_conclusion: success
          name: packages
          path: dist
          if_no_artifact_found: fail
      - name: upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: packages
          path: dist

  # test packages
  test:
    name: testing tutorial
    needs: build
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macOS-latest]
        test: [coreA, coreB, extensions]
        python: [3.8, 3.11]
    runs-on: ${{ matrix.os }}
    steps:
      - name: starting
        uses: actions/checkout@v3
      - name: pipPreOrNot
        run: |
          echo "PIPPRE=--pre" >> $GITHUB_ENV
      - name: setup python ${{ matrix.python }}
        uses: actions/setup-python@v3
        with:
          python-version: ${{ matrix.python }}
      - name: download artifacts
        uses: actions/download-artifact@v3
        # if all packages exist on pypi then no artifacts are uploaded so don't fail
        continue-on-error: true
        with:
          name: packages
          path: dist
      - name: Install dependencies
        run: |
          if [ "$RUNNER_OS" == "Linux" ]; then
            # note: using 'apt-get -o Acquire::Retries=3' to dance around connectivity issues to Azure,
            # use apt-spy2 to select closest apt mirror,
            # which helps avoid connectivity issues in Azure;
            # see https://github.com/actions/virtual-environments/issues/675
            sudo gem install apt-spy2
            sudo apt-spy2 check
            sudo apt-spy2 fix --commit
            # after selecting a specific mirror, we need to run 'apt-get update'
            sudo apt-get update -o Acquire::Retries=3
            sudo apt upgrade -y
            sudo apt-get install libopenmpi-dev openmpi-bin libsuperlu-dev libsuitesparse-dev petsc-dev gmsh python3-petsc4py-real
          elif [ "$RUNNER_OS" == "macOS" ]; then
            # rm -rf /usr/local/bin/2to3* # otherwise a python upgrade fails in next step
            brew update || true
            brew install openmpi superlu suite-sparse gmsh boost || true
          fi
        shell: bash
      - name: Setup venv
        run: |
          python3 -m venv dune-env
          source dune-env/bin/activate
          PYVERS=$(python3 --version)
          echo "Selected python version $PYVERS"
          pip3 install --upgrade pip
          pip3 install matplotlib scipy scikit-build mpi4py pygmsh wheel
          if [ "$RUNNER_OS" == "Linux" ]; then
            echo "CURRENTLY PETSC4PY IS DISABLED"
            # petsc4py is failing at the moment - need to check
            # at the moment need to downgrade to 20.0.2 https://gitlab.com/petsc/petsc/-/issues/1369
            # PETSC_CONFIGURE_OPTIONS="--download-scalapack --download-suitesparse --download-hypre --download-mumps --download-ml --download-superlu"
            # pip3 install -v petsc petsc4py
          else
            echo "CURRENTLY PETSC4PY IS DISABLED on MACOs due to issues with mpif90 - needs checking"
            # while building petsc the following error is produced
            #     Fortran compiler you provided with --with-fc=/usr/local/bin/mpif90 cannot be found or does not work.
            #     Cannot compile FC with /usr/local/bin/mpif90.
          fi
        shell: bash
      - name: pip3 install dune modules
        run: |
          ls dist
          source dune-env/bin/activate
          pip3 install extract-version
          python extractreq.py
          cat requirements.txt
          if [ "$FEMVERSION" == "" ]; then
            pip3 install $PIPPRE  -U -v --find-links file://$PWD/dist -r requirements.txt
          else
            pip3 install $PIPPRE  -U -v --find-links file://$PWD/dist -r requirements.txt
          fi
        shell: bash
      - name: Setup dune-py
        run: |
          set +e
          source dune-env/bin/activate
          pip3 list
          python -m dune.fem # tutorial
        shell: bash
      - name: Run tutorial
        run: |
          set +e
          source dune-env/bin/activate
          echo "USING python"
          python --version
          export DUNEPY_DISABLE_PLOTTING=1
          export DUNE_LOG_LEVEL=$LOGLEVEL
          cd fem_tutorial
          python ../run-tutorial.py ${{ matrix.test }}
        shell: bash

  # https://github.com/marketplace/actions/pypi-publish
  upload:
    name: uploading
    env:
      UPLOAD: none
    needs: test
    runs-on: [ubuntu-latest]
    steps:
      - name: environment
        if: github.event.inputs.upload != ''
        run: echo "UPLOAD=${{ github.event.inputs.upload }}" >> $GITHUB_ENV
      - name: download artifacts
        uses: actions/download-artifact@v3
        continue-on-error: true
        with:
          name: packages
          path: dist
      - name: remove repository tar.gz since it can't be uploaded
        run: |
          rm dist/repos.tar.gz
        shell: bash
      - name: Publish package to ${{ env.UPLOAD }}
        uses: pypa/gh-action-pypi-publish@release/v1
        if: ${{ env.UPLOAD == 'pypi' }}
        with:
          user: __token__
          password: ${{ secrets.PYPI_API_TOKEN }}
      - name: Publish package to ${{ env.UPLOAD }}
        uses: pypa/gh-action-pypi-publish@release/v1
        if: ${{ env.UPLOAD == 'testpypi' }}
        with:
          user: __token__
          password: ${{ secrets.TEST_PYPI_API_TOKEN }}
          repository_url: https://test.pypi.org/legacy/
          ## this is needed so long as versioning for
          ## fem and core packages can differ (i.e. 2.8.0.x) but are uploaded
          ## in same script.
          ## Test if required version for core is available on pypi and use
          ## instead of git?
          # skip_existing: true
